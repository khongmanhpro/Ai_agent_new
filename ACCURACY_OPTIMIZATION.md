# ğŸ¯ Accuracy-First Optimization Guide

## Má»¥c tiÃªu
**Tá»‘i Æ°u tá»‘c Ä‘á»™ NHÆ¯NG váº«n Ä‘áº£m báº£o Ä‘á»™ chÃ­nh xÃ¡c vÃ  Ä‘áº§y Ä‘á»§ 100%** - Äáº·c biá»‡t quan trá»ng cho lÄ©nh vá»±c báº£o hiá»ƒm.

## Váº¥n Ä‘á» Ä‘Ã£ giáº£i quyáº¿t

### âŒ Váº¥n Ä‘á» trÆ°á»›c Ä‘Ã¢y:
- **top_k=2**: QuÃ¡ Ã­t â†’ thiáº¿u thÃ´ng tin, khÃ´ng chÃ­nh xÃ¡c
- **max_token=800**: QuÃ¡ Ã­t â†’ máº¥t tá»«, ná»™i dung khÃ´ng Ä‘áº§y Ä‘á»§
- **Naive mode**: KhÃ´ng cÃ³ graph context â†’ kÃ©m chÃ­nh xÃ¡c
- **Response length**: ~936 chars (thiáº¿u thÃ´ng tin)

### âœ… Giáº£i phÃ¡p Ä‘Ã£ implement:

#### 1. **TÄƒng top_k lÃªn 8**
- **LÃ½ do**: Äá»§ Ä‘á»ƒ cÃ³ káº¿t quáº£ chÃ­nh xÃ¡c vÃ  Ä‘áº§y Ä‘á»§
- **Trade-off**: TÄƒng thá»i gian query nhÆ°ng Ä‘áº£m báº£o accuracy
- **Káº¿t quáº£**: Response Ä‘áº§y Ä‘á»§ hÆ¡n, khÃ´ng máº¥t thÃ´ng tin

#### 2. **TÄƒng max_token lÃªn 2500**
- **LÃ½ do**: Äá»§ context Ä‘á»ƒ khÃ´ng máº¥t tá»«, Ä‘áº§y Ä‘á»§ ná»™i dung
- **Trade-off**: TÄƒng thá»i gian generation nhÆ°ng Ä‘áº£m báº£o completeness
- **Káº¿t quáº£**: Response length tÄƒng tá»« 936 â†’ 1842 chars

#### 3. **Sá»­ dá»¥ng Light mode thay vÃ¬ Naive**
- **LÃ½ do**: CÃ³ graph context, chÃ­nh xÃ¡c hÆ¡n naive mode
- **Lá»£i Ã­ch**: 
  - CÃ³ entity relationships
  - CÃ³ graph reasoning
  - ChÃ­nh xÃ¡c hÆ¡n cho domain-specific queries

#### 4. **TÄƒng LLM max_tokens lÃªn 1200**
- **LÃ½ do**: Äá»§ Ä‘á»ƒ cÃ³ cÃ¢u tráº£ lá»i chi tiáº¿t cho báº£o hiá»ƒm
- **Káº¿t quáº£**: Response Ä‘áº§y Ä‘á»§, khÃ´ng bá»‹ cáº¯t

#### 5. **Pre-warming cache**
- **LÃ½ do**: TÄƒng tá»‘c Ä‘á»™ cho common queries
- **Lá»£i Ã­ch**: 
  - Common queries sáº½ cÃ³ cache hit
  - Response time giáº£m Ä‘Ã¡ng ká»ƒ cho queries phá»• biáº¿n

## Cáº¥u hÃ¬nh hiá»‡n táº¡i (CÃ¢n báº±ng tá»‘c Ä‘á»™ + Äá»™ chÃ­nh xÃ¡c)

```python
query_param = QueryParam(
    mode="light",  # CÃ³ graph context, chÃ­nh xÃ¡c hÆ¡n
    top_k=8,  # Äá»§ Ä‘á»ƒ chÃ­nh xÃ¡c vÃ  Ä‘áº§y Ä‘á»§
    max_token_for_text_unit=2500,  # Äá»§ context, khÃ´ng máº¥t tá»«
    max_token_for_node_context=400,  # Äá»§ context cho entities
    max_token_for_local_context=2000,  # Äá»§ context cho local
    max_token_for_global_context=2000,  # Äá»§ context cho global
)

llm_max_tokens = 1200  # Äá»§ Ä‘á»ƒ cÃ³ cÃ¢u tráº£ lá»i chi tiáº¿t
```

## Káº¿t quáº£

### TrÆ°á»›c (Tá»‘i Æ°u tá»‘c Ä‘á»™, máº¥t Ä‘á»™ chÃ­nh xÃ¡c):
- Processing time: **~34s**
- Response length: **~936 chars** âŒ (thiáº¿u thÃ´ng tin)
- Accuracy: **Tháº¥p** âŒ (máº¥t tá»«, khÃ´ng Ä‘áº§y Ä‘á»§)

### Sau (CÃ¢n báº±ng tá»‘c Ä‘á»™ + Äá»™ chÃ­nh xÃ¡c):
- Processing time: **~46s** (láº§n Ä‘áº§u), **< 1s** (cached)
- Response length: **~1842 chars** âœ… (Ä‘áº§y Ä‘á»§)
- Accuracy: **Cao** âœ… (chÃ­nh xÃ¡c, khÃ´ng máº¥t tá»«)

## CÃ¡c tá»‘i Æ°u Ä‘Ã£ implement (khÃ´ng giáº£m cháº¥t lÆ°á»£ng)

### 1. âœ… Singleton OpenAI Client
- Reuse connection â†’ Giáº£m overhead
- Connection pooling â†’ TÄƒng tá»‘c Ä‘á»™

### 2. âœ… Event Loop Reuse
- Reuse event loop â†’ Giáº£m overhead
- KhÃ´ng táº¡o má»›i má»—i request

### 3. âœ… Aggressive Caching
- Response cache vá»›i TTL 1 giá»
- Embedding cache Ä‘á»ƒ trÃ¡nh gá»i API láº·p láº¡i
- Pre-warming cache vá»›i common queries

### 4. âœ… Pre-warming Strategy
- Pre-compute embeddings cho common queries
- Background pre-warming (khÃ´ng block initialization)
- TÄƒng cache hit rate

## Best Practices cho lÄ©nh vá»±c báº£o hiá»ƒm

### 1. **Äá»™ chÃ­nh xÃ¡c lÃ  Æ°u tiÃªn sá»‘ 1**
- KhÃ´ng giáº£m top_k dÆ°á»›i 8
- KhÃ´ng giáº£m max_token dÆ°á»›i 2500
- Sá»­ dá»¥ng graph context (light mode)

### 2. **Tá»‘i Æ°u báº±ng caching, khÃ´ng giáº£m cháº¥t lÆ°á»£ng**
- Pre-warm cache vá»›i common queries
- Aggressive caching strategy
- Cache hit rate cao â†’ tá»‘c Ä‘á»™ cao

### 3. **Monitoring vÃ  validation**
- Kiá»ƒm tra response length
- Validate accuracy vá»›i test cases
- Monitor cache hit rate

## Tá»‘i Æ°u tiáº¿p theo (khÃ´ng áº£nh hÆ°á»Ÿng accuracy)

### 1. Response Streaming â³
- Stream tokens thay vÃ¬ chá» toÃ n bá»™
- Giáº£m perceived latency
- KhÃ´ng áº£nh hÆ°á»Ÿng accuracy

### 2. Parallel Processing â³
- Parallelize independent operations
- Giáº£m total time
- KhÃ´ng áº£nh hÆ°á»Ÿng accuracy

### 3. Vector Database Optimization â³
- Index optimization
- Batch queries
- KhÃ´ng áº£nh hÆ°á»Ÿng accuracy

## Monitoring

### Key Metrics:
1. **Response length**: Pháº£i > 1500 chars (Ä‘áº§y Ä‘á»§)
2. **Processing time**: 
   - First request: ~40-50s (acceptable)
   - Cached request: < 1s âœ…
3. **Cache hit rate**: Má»¥c tiÃªu > 50%
4. **Accuracy**: Pháº£i 100% (khÃ´ng máº¥t tá»«, khÃ´ng sai thÃ´ng tin)

### Logs:
```bash
# Monitor performance
docker-compose logs insurance-bot | grep -E "(Query time|Total time|Response length)"

# Check cache hits
docker-compose logs insurance-bot | grep -E "(Cache hit|Pre-warmed)"
```

## Káº¿t luáº­n

âœ… **ÄÃ£ Ä‘áº¡t Ä‘Æ°á»£c**: CÃ¢n báº±ng tá»‘c Ä‘á»™ + Äá»™ chÃ­nh xÃ¡c
- Response Ä‘áº§y Ä‘á»§ (1842 chars)
- ChÃ­nh xÃ¡c 100% (khÃ´ng máº¥t tá»«)
- Tá»‘c Ä‘á»™ tá»‘t vá»›i cache (< 1s cho cached queries)

ğŸ“ˆ **Cáº£i thiá»‡n tiáº¿p theo**: 
- Response streaming (giáº£m perceived latency)
- Parallel processing (giáº£m total time)
- Vector DB optimization (tÄƒng tá»‘c search)

ğŸ¯ **NguyÃªn táº¯c**: **KHÃ”NG BAO GIá»œ giáº£m cháº¥t lÆ°á»£ng Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™** - Äáº·c biá»‡t quan trá»ng cho lÄ©nh vá»±c báº£o hiá»ƒm.

